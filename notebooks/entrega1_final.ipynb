{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ASUM-DM Methodology Analysis - Caso 1: Clustering\n",
                "\n",
                "## 1. Etapas de Entendimiento\n",
                "\n",
                "### 1.1 Comprensión del Negocio\n",
                "**Objetivo:** Definir el problema, los objetivos de negocio y los requisitos de la solución.\n",
                "\n",
                "**Problema:** Una empresa de retail busca implementar estrategias de marketing diferenciadas segmentando a sus clientes según su comportamiento.\n",
                "\n",
                "**Objetivo de Negocio:** Confirmar o rechazar la hipótesis del equipo de mercadeo de que los clientes se pueden dividir en **3 grupos**.\n",
                "\n",
                "### 1.2 Enfoque Analítico\n",
                "**Tipo de Problema:** Aprendizaje no supervisado (Clustering).\n",
                "\n",
                "**Métodos de Construcción:** Se utilizarán y compararán cuatro algoritmos de agrupamiento:\n",
                "1. **K-Means:** Método de partición basado en centroides\n",
                "2. **Método Jerárquico Aglomerativo (MJA):** Clustering jerárquico con dendrogramas\n",
                "3. **DBSCAN:** Método basado en densidad\n",
                "4. **Gaussian Mixture Models (GMM):** Método basado en distribución probabilística"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Etapas de Preparación\n",
                "\n",
                "### 2.1 Recopilación y Carga de Datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "sys.path.append(os.path.abspath('..'))\n",
                "\n",
                "from utils.entrega1.data_loader import load_data\n",
                "\n",
                "df = load_data('../data/datos_caso_1.csv')\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Comprensión de Datos - Análisis Exploratorio (EDA)\n",
                "\n",
                "#### Estadísticas Básicas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.entrega1.eda import get_basic_stats\n",
                "\n",
                "display(get_basic_stats(df).T)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Valores Faltantes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.entrega1.eda import check_missing_values_viz\n",
                "\n",
                "check_missing_values_viz(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Distribuciones de Variables Numéricas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.entrega1.eda import plot_distributions_numerical\n",
                "\n",
                "numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
                "plot_distributions_numerical(df, numerical_cols)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Boxplots para Detección de Outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.entrega1.eda import plot_boxplots\n",
                "\n",
                "plot_boxplots(df, numerical_cols)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Variables Categóricas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.entrega1.eda import plot_pie_categorical\n",
                "\n",
                "plot_pie_categorical(df, ['Education', 'Marital_Status'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Matriz de Correlación"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.entrega1.eda import plot_correlation_matrix\n",
                "\n",
                "plot_correlation_matrix(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Preprocesamiento de Datos\n",
                "\n",
                "Aplicamos el pipeline de preprocesamiento que incluye:\n",
                "- Manejo de valores faltantes\n",
                "- Eliminación y transformación de valores atípicos\n",
                "- Ingeniería de características (Age, Days_Being_Customer, Total_Mnt, etc.)\n",
                "- Codificación de variables categóricas (One-Hot Encoding)\n",
                "- Escalado de características numéricas (StandardScaler)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.entrega1.preprocessing import preprocess_pipeline\n",
                "\n",
                "(\n",
                "    df_scaled,\n",
                "    scaler,\n",
                "    encoder,\n",
                "    all_feature_cols,\n",
                "    num_feature_cols,\n",
                "    ohe_feature_cols,\n",
                "    categorical_cols,\n",
                ") = preprocess_pipeline(df)\n",
                "\n",
                "print(f'Dataset después del preprocesamiento: {df_scaled.shape}')\n",
                "print(f'Características numéricas: {len(num_feature_cols)}')\n",
                "print(f'Características OHE: {len(ohe_feature_cols)}')\n",
                "print(f'Total de características: {len(all_feature_cols)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Modelado - K-Means\n",
                "\n",
                "### 3.1 Método del Codo y Silhouette Score\n",
                "\n",
                "Determinamos el número óptimo de clusters analizando la inercia y el Silhouette Score.\n",
                "La línea roja punteada indica la hipótesis de negocio (k=3)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.cluster import KMeans\n",
                "from utils.entrega1.modeling import evaluate_clusters_kmeans\n",
                "\n",
                "evaluate_clusters_kmeans(\n",
                "    df_scaled,\n",
                "    range_n_clusters=range(2, 11),\n",
                "    include_silhouette=True,\n",
                "    ref_cluster=3,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Entrenamiento del Modelo K-Means Final"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_clusters_kmeans = 3\n",
                "kmeans_final = KMeans(n_clusters=n_clusters_kmeans, random_state=42, n_init=10)\n",
                "kmeans_labels = kmeans_final.fit_predict(df_scaled)\n",
                "\n",
                "print('K-Means - Distribución de clusters:')\n",
                "print(pd.Series(kmeans_labels).value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 Interpretación de Clusters K-Means\n",
                "\n",
                "Analizamos los centroides de cada cluster en su escala original mediante transformación inversa."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Centros escalados\n",
                "centers_scaled = pd.DataFrame(kmeans_final.cluster_centers_, columns=all_feature_cols)\n",
                "\n",
                "# Transformación inversa - numéricas\n",
                "centers_num_inverse = scaler.inverse_transform(centers_scaled[num_feature_cols])\n",
                "centers_num_df = pd.DataFrame(centers_num_inverse, columns=num_feature_cols)\n",
                "\n",
                "# Transformación inversa - categóricas\n",
                "centers_cat_inverse = encoder.inverse_transform(centers_scaled[ohe_feature_cols])\n",
                "centers_cat_df = pd.DataFrame(centers_cat_inverse, columns=categorical_cols)\n",
                "\n",
                "# Combinar\n",
                "centers_original = pd.concat([centers_num_df, centers_cat_df], axis=1)\n",
                "\n",
                "print('=== Centroides de K-Means (Escala Original) ===')\n",
                "display(centers_original.T)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Modelado - Método Jerárquico Aglomerativo (MJA)\n",
                "\n",
                "### 4.1 Dendrograma\n",
                "\n",
                "Visualizamos la jerarquía de clusters para determinar el número óptimo de grupos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.cluster import AgglomerativeClustering\n",
                "from utils.entrega1.modeling import plot_dendrogram\n",
                "\n",
                "# Para el dendrograma necesitamos el árbol completo\n",
                "hierarchical_full = AgglomerativeClustering(\n",
                "    distance_threshold=0,\n",
                "    n_clusters=None,\n",
                "    linkage='ward',\n",
                ")\n",
                "hierarchical_full.fit(df_scaled)\n",
                "\n",
                "plt.figure(figsize=(14, 8))\n",
                "plt.title('Dendrograma - Método Jerárquico Aglomerativo')\n",
                "plot_dendrogram(hierarchical_full, truncate_mode='level', p=5)\n",
                "plt.xlabel('Índice de la muestra (o tamaño del cluster)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Entrenamiento del Modelo Jerárquico"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_clusters_hierarchical = 3\n",
                "hierarchical = AgglomerativeClustering(\n",
                "    n_clusters=n_clusters_hierarchical,\n",
                "    linkage='ward',\n",
                ")\n",
                "hierarchical_labels = hierarchical.fit_predict(df_scaled)\n",
                "\n",
                "print('MJA - Distribución de clusters:')\n",
                "print(pd.Series(hierarchical_labels).value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Modelado - DBSCAN\n",
                "\n",
                "### 5.1 Estimación de Epsilon (k-NN Distance)\n",
                "\n",
                "Utilizamos el método del k-NN distance para estimar el valor de epsilon."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.cluster import DBSCAN\n",
                "from utils.entrega1.modeling import plot_knn_distance, optimize_dbscan_grid\n",
                "\n",
                "plot_knn_distance(df_scaled, k=5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 Optimización de Hiperparámetros (Grid Search)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "dbscan_results_df = optimize_dbscan_grid(\n",
                "    df_scaled,\n",
                "    eps_values=np.arange(1.0, 5.0, 0.5),\n",
                "    min_samples_values=[3, 5, 7, 10],\n",
                ")\n",
                "\n",
                "# Seleccionar mejores parámetros\n",
                "best_row = dbscan_results_df.loc[dbscan_results_df['Score'].idxmax()]\n",
                "best_eps = best_row['Epsilon']\n",
                "best_min_samples = int(best_row['Vecindad'])\n",
                "print(f'Mejores parámetros: eps={best_eps}, min_samples={best_min_samples}, score={best_row[\"Score\"]:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.3 Entrenamiento del Modelo DBSCAN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
                "dbscan_labels = dbscan.fit_predict(df_scaled)\n",
                "\n",
                "print('DBSCAN - Distribución de clusters:')\n",
                "print(pd.Series(dbscan_labels).value_counts().sort_index())\n",
                "print(f'\\nPuntos de ruido (label=-1): {(dbscan_labels == -1).sum()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Modelado - Gaussian Mixture Models (GMM)\n",
                "\n",
                "### 6.1 Selección del Número de Componentes (BIC)\n",
                "\n",
                "Utilizamos el Criterio de Información Bayesiano (BIC) para determinar el número óptimo de componentes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.mixture import GaussianMixture\n",
                "from utils.entrega1.modeling import evaluate_gmm_bic\n",
                "\n",
                "evaluate_gmm_bic(\n",
                "    df_scaled,\n",
                "    n_components_range=range(2, 11),\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.2 Entrenamiento del Modelo GMM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_components_gmm = 3\n",
                "gmm = GaussianMixture(\n",
                "    n_components=n_components_gmm,\n",
                "    covariance_type='full',\n",
                "    random_state=42,\n",
                ")\n",
                "gmm_labels = gmm.fit_predict(df_scaled)\n",
                "\n",
                "print('GMM - Distribución de clusters:')\n",
                "print(pd.Series(gmm_labels).value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Comparación de Modelos\n",
                "\n",
                "### 7.1 Silhouette Score\n",
                "\n",
                "Comparamos todos los modelos utilizando el Silhouette Score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.entrega1.modeling import compare_all_models_silhouette\n",
                "\n",
                "models_dict = {\n",
                "    'K-Means': kmeans_labels,\n",
                "    'Jerárquico': hierarchical_labels,\n",
                "    'DBSCAN': dbscan_labels,\n",
                "    'GMM': gmm_labels,\n",
                "}\n",
                "\n",
                "scores = compare_all_models_silhouette(df_scaled, models_dict)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2 Visualización con PCA\n",
                "\n",
                "Reducimos la dimensionalidad a 2D para visualizar los clusters de cada modelo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.entrega1.modeling import visualize_clusters_pca\n",
                "\n",
                "for name, labels in models_dict.items():\n",
                "    visualize_clusters_pca(df_scaled, labels, title=f'{name} Clusters (PCA)')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Conclusiones\n",
                "\n",
                "### 8.1 Resumen de Resultados\n",
                "\n",
                "Basándonos en el análisis realizado:\n",
                "\n",
                "1. **K-Means** y **Método Jerárquico** confirman la hipótesis de negocio de 3 clusters\n",
                "2. **DBSCAN** identifica clusters basados en densidad y puede detectar outliers\n",
                "3. **GMM** proporciona asignación probabilística a los clusters\n",
                "\n",
                "### 8.2 Recomendaciones\n",
                "\n",
                "- El modelo **K-Means** es recomendado por su simplicidad e interpretabilidad\n",
                "- Los 3 clusters identificados permiten estrategias de marketing diferenciadas\n",
                "- Se recomienda validar los resultados con el equipo de negocio"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbformat_minor": 4,
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}